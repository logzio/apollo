export const servicesMock = [
  {
    id: 1,
    name: 'sample-apollo-app',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: sample-apollo-app\n  name: sample-apollo-app\n  namespace: default\nspec:\n  replicas: 2\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: sample-apollo-app\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/sample-apollo-app\n        imagePullPolicy: Always\n        name: sample-apollo-app\n        ports:\n        - containerPort: 80\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 80\n          initialDelaySeconds: 30\n          periodSeconds: 1\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 5',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: sample-apollo-app\n  name: sample-apollo-app-service\n  namespace: default\nspec:  \n  ports:\n  - nodePort: 30005\n    port: 80\n    protocol: TCP\n    targetPort: 80\n  selector:\n    role: sample-apollo-app\n  type: NodePort',
    ingressYaml: null,
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 2,
    name: 'apollo',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: apollo\n    service: apollo\n  name: apollo\n  namespace: prod\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      role: apollo\n  strategy:\n    rollingUpdate:\n      maxSurge: 0\n      maxUnavailable: 1\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: apollo\n    spec:\n      containers:\n      - env:\n        - name: APOLLO_CONSUL_URL\n          value: consul.internal.logz.io:8500\n        - name: APOLLO_CONSUL_KEY\n          value: logzio-configurations/prod/us-east-1/apollo/apollo.conf\n        - name: LOGZIO_URL\n          value: https://listener.logz.io:8071\n        - name: LOGZIO_TOKEN\n          value: YZZXfOLKfTJEMGgKknWaKOpURnvALnRi\n        - name: APOLLO_LOGBACK_XML_PATH\n          value: /etc/apollo/apollo-logback.xml\n        - name: ENV\n          value: PROD\n        - name: REGION\n          value: us-east-1\n    spec:\n      containers:\n      - env:\n        - name: APOLLO_CONSUL_URL\n          value: consul.internal.logz.io:8500\n        - name: APOLLO_CONSUL_KEY\n          value: logzio-configurations/prod/us-east-1/apollo/apollo.conf\n        - name: LOGZIO_URL\n          value: https://listener.logz.io:8071\n        - name: LOGZIO_TOKEN\n          value: YZZXfOLKfTJEMGgKknWaKOpURnvALnRi\n        - name: APOLLO_LOGBACK_XML_PATH\n          value: /etc/apollo/apollo-logback.xml\n        - name: ENV\n          value: PROD\n        - name: REGION\n          value: us-east-1\n        image: logzio/apollo\n        imagePullPolicy: Always\n        livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /api/health\n            port: 80\n            scheme: HTTP\n          initialDelaySeconds: 45\n          periodSeconds: 5\n          successThreshold: 1\n          timeoutSeconds: 1\n        name: apollo\n        ports:\n        - containerPort: 80\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /api/health\n            port: 80\n            scheme: HTTP\n          initialDelaySeconds: 45\n          periodSeconds: 5\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 512Mi\n        volumeMounts:\n        - mountPath: /etc/apollo\n          name: config-volume\n      dnsPolicy: ClusterFirst\n      restartPolicy: Always\n      schedulerName: default-scheduler\n      terminationGracePeriodSeconds: 5\n      volumes:\n      - configMap:\n          defaultMode: 420\n          name: apollo\n        name: config-volume',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: apollo\n  name: apollo-service\nspec:  \n  ports:\n  - nodePort: 30001\n    port: 80\n    protocol: TCP\n    targetPort: 80\n  selector:\n    role: apollo\n  type: NodePort\n',
    ingressYaml: null,
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 3,
    name: 'app-api',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata: \n  labels: \n    role: app\n  name: app\nspec: \n  replicas: 3\n  revisionHistoryLimit: 3\n  strategy: \n    rollingUpdate: \n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template: \n    metadata: \n      labels: \n        role: app\n    spec: \n      containers: \n        - name: app-node\n          image: "registry.internal.logz.io:5000/app-api"\n          imagePullPolicy: Always\n          ports: \n            - \n              containerPort: 9000\n              protocol: TCP\n          resources: \n            requests: \n              cpu: 100m\n              memory: 512Mi\n          volumeMounts: \n            - \n              mountPath: /work\n              name: app-frontend-storage\n        - name: app-nginx\n          command: \n            - sh\n            - "-c"\n            - "echo \'127.0.0.1 app\' >> /etc/hosts ; nginx -g \'daemon off;\'"\n          image: "registry.internal.logz.io:5000/frontend-nginx:1.11.1-v1"\n          imagePullPolicy: Always\n          livenessProbe: \n            httpGet: \n              path: /__admin__/utils/healthiness\n              port: 8080\n            initialDelaySeconds: 30\n            periodSeconds: 10\n            failureThreshold: 3\n          ports: \n            - \n              containerPort: 8080\n              protocol: TCP\n            - \n              containerPort: 80\n              protocol: TCP\n          readinessProbe: \n            httpGet: \n              path: /__admin__/utils/readiness\n              port: 8080\n            initialDelaySeconds: 30\n            periodSeconds: 1\n            failureThreshold: 1\n          resources: \n            requests: \n              cpu: 20m\n              memory: 64Mi\n          volumeMounts: \n            - \n              mountPath: /sites/app\n              name: app-frontend-storage\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 0\n      volumes: \n        - \n          emptyDir: {}\n          name: app-frontend-storage',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata: \n  labels: \n    role: app\n  name: app-service\n  {{ annotations }}\n    {{ internalLB }}\nspec: \n  ports: \n    - name: nginx\n      {{ nodePortNginx }}\n      port: 8080\n      targetPort: 8080\n    - name: nginxredirect\n      {{ nodePortNginxredirect }}\n      port: 80\n      targetPort: 80\n    - name: node\n      port: 9000\n      targetPort: 9000\n  selector: \n    role: app\n  type: {{ type }}',
    ingressYaml: null,
    defaultShell: '/bin/sh',
    isPartOfGroup: false,
  },
  {
    id: 6,
    name: 'servicesMock',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: servicesMock\n  name: servicesMock\nspec:\n  replicas: 2\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: servicesMock\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/servicesMock\n        imagePullPolicy: Always\n        name: servicesMock\n        resources:\n          requests:\n            cpu: 150m\n            memory: 6144Mi\n        ports:\n        - containerPort: 8060\n          protocol: TCP\n        - containerPort: 9090\n          protocol: TCP\n        - containerPort: 9990\n          protocol: TCP\n        - containerPort: 5701\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 8000\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 180\n          periodSeconds: 20\n        livenessProbe:\n            httpGet:\n              path: /system/health\n              port: 9990\n            initialDelaySeconds: 180\n            periodSeconds: 20\n\n      - image: saltsecurity/agent:4.7.4\n        imagePullPolicy: Always\n        name: salt-agent\n        env:\n        - name: SALT_BACKEND_PORT\n          value: "30443"\n        - name: SALT_WS_DOMAIN\n          value: wss://salt-api-proxy.internal.logz.io:30444/api/agent/v1\n        - name: SALT_TOKEN\n          value: gjvvojevlmhbp2qyilzb3titqfuhmbmrerb8khlg03i51mnmm7827njsnpzbyi22\n        - name: SALT_DOMAIN\n          value: salt-api-proxy.internal.logz.io\n        - name: SALT_SSL\n          value: any\n        - name: SEND_LOGS_FLAG\n          value: "no"\n        - name: SALT_LOGS_URL\n          value: servicesMock.dnssf.com:3832\n        - name: SALT_EXTRA\n          value: {{ salt_extra }}',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: servicesMock\n  name: servicesMock-service\nspec:\n  ports:\n  - nodePort: 30003\n    port: 8060\n    protocol: TCP\n    targetPort: 8060\n    name: servicesMock-legacy\n  - nodePort: 30004\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: servicesMock-new\n  selector:\n    role: servicesMock\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: servicesMock-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: servicesMock-camel-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: servicesMock-service\n          servicePort: 8060\n        path: /\n  - host: servicesMock-jersey-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: servicesMock-service\n          servicePort: 9990\n        path: /\n  - host: servicesMock-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: servicesMock-service\n          servicePort: 9990\n        path: /',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 7,
    name: 'tasks',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: tasks\n  name: tasks\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 0\n      maxUnavailable: 1\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: tasks\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/tasks\n        imagePullPolicy: Always\n        name: tasks\n        resources:\n          requests:\n            cpu: 150m\n            memory: 8192Mi\n        ports:\n        - containerPort: 8778\n          name: jolokia\n          protocol: TCP\n        - containerPort: 9090\n          name: jmx\n          protocol: TCP\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 16000\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 180\n          periodSeconds: 30\n          timeoutSeconds: 5\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 180\n          periodSeconds: 30\n          timeoutSeconds: 5',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: tasks\n  name: tasks-service\nspec:\n  ports:\n  - nodePort: 30006\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: tasks\n  selector:\n    role: tasks\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: tasks-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: tasks-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: tasks-service\n          servicePort: 9990\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 8,
    name: 'atlas-cluster',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: atlas\n  name: atlas\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: atlas\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - name: atlas\n        image: registry.internal.logz.io:5000/atlas-engine\n        imagePullPolicy: Always\n        resources:\n          requests:\n            cpu: 50m\n            memory: 2048Mi\n        ports:\n        - containerPort: 8778\n          name: jolokia\n          protocol: TCP\n        - containerPort: 9090\n          name: jmx\n          protocol: TCP\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: ATLAS_ROLES\n          value: {{ atlas_roles }}\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 4000\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 120\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 180\n          periodSeconds: 20\n      - name: selenium\n        image: registry.internal.logz.io:5000/selenium:3.4.0\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 4444\n          name: selenium\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 120\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 180\n          periodSeconds: 10',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: atlas\n  name: atlas-service\nspec:\n  ports:\n  - nodePort: 30015\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: atlas\n  selector:\n    role: atlas\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: atlas-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: atlas-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: atlas-service\n          servicePort: 9990\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: true,
  },
  {
    id: 9,
    name: 'logengine',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: logengine\n  name: logengine\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: logengine\n        apollo_jolokia_port: 9990\n    spec:\n      nodeSelector:\n        {{az_label}} {{logengine_az}}    \n      containers:\n      - image: registry.internal.logz.io:5000/log-engine\n        imagePullPolicy: Always\n        name: logengine\n        resources:\n          requests:\n            cpu: 1000m\n            memory: 1536Mi\n        lifecycle:\n          preStop:\n            exec:\n              command: ["/bin/sh", "-c", "sleep 60;/root/graceful_stop.bash --sync"]\n        ports:\n        - containerPort: 4000\n          name: from-logstash\n        - containerPort: 4020\n          name: to-logstash\n        - containerPort: 8778\n          name: jolokia\n          protocol: TCP\n        - containerPort: 9090\n          name: jmx\n          protocol: TCP\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: LOGENGINE_ROLES\n          value: {{ logengine_roles }}\n        - name: FETCH\n          value: "no_fetch"\n        - name: KAFKA_LE_TOPIC\n          value: {{ kafka_topic }}\n        - name: KAFKA_LE_GROUP\n          value: "indexing"\n        - name: KAFKA_REBALANCE_MAX_RETRIES\n          value: "15"\n        - name: KAFKA_REBALANCE_BACKOFF_MILLIS\n          value: "20000"\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 3001\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 10\n          periodSeconds: 30\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 10\n          periodSeconds: 30\n          failureThreshold: 6\n      terminationGracePeriodSeconds: 1800',
    serviceYaml: null,
    ingressYaml: null,
    defaultShell: null,
    isPartOfGroup: true,
  },
  {
    id: 12,
    name: 'tailer',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: log-tailer\n  name: log-tailer\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: log-tailer\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/nginx-ssl-termination-livetail:180518-1\n        imagePullPolicy: Always\n        name: ssl-termination\n        resources:\n          requests:\n            cpu: 100m\n            memory: 512Mi\n        ports:\n        - containerPort: 443\n          name: websokect-ssl\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            scheme: HTTPS\n            path: /health\n            port: 443\n          initialDelaySeconds: 30\n          periodSeconds: 30\n      - image: registry.internal.logz.io:5000/log-tailer\n        imagePullPolicy: Always\n        name: log-tailer\n        resources:\n          requests:\n            cpu: 1\n            memory: 4096Mi\n        lifecycle:\n          preStop:\n            exec:\n              command: ["/root/graceful_stop.bash"]\n        ports:\n        - containerPort: 8888\n          name: websokect\n          protocol: TCP\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 3000\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8888\n          initialDelaySeconds: 60\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20\n      terminationGracePeriodSeconds: 1800',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: log-tailer-data\n  name: log-tailer-service\nspec:\n  ports:\n  - {{ nodePortHttps }}\n    port: 443\n    protocol: TCP\n    targetPort: 443\n    name: log-tailer-data\n  - {{ nodePortEngine }}\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: log-tailer-api\n  selector:\n    role: log-tailer\n  type: {{ type }}',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: tailer-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: tailer-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: log-tailer-service\n          servicePort: 9990\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 13,
    name: 'scanner',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: scanner\n  name: scanner\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: scanner\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/log-scanner\n        imagePullPolicy: Always\n        name: scanner\n        resources:\n          requests:\n            cpu: 2000m\n            memory: 3072Mi\n        ports:\n        - containerPort: 9990\n          name: rest\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: KAFKA_SCANNER_TOPICS_LABEL_SELECTOR\n          value: {{ topics_label_selector }}\n        - name: KAFKA_SCANNER_GROUP\n          value: {{ kafka_group }}\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 4096\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 120\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 120\n          periodSeconds: 10\n      nodeSelector:\n        {{az_label}} {{availability_zone}}\n        {{scanners_enabled}}\n      tolerations:\n      - key: "dedicated"\n        value: "scanners"',
    serviceYaml: null,
    ingressYaml: null,
    defaultShell: null,
    isPartOfGroup: true,
  },
  {
    id: 14,
    name: 'templates-validator',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: templates-validator\n  name: templates-validator\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: templates-validator\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/templates-validator\n        imagePullPolicy: Always\n        name: templates-validator\n        resources:\n          requests:\n            cpu: 20m\n            memory: 1536Mi\n        ports:\n        - containerPort: 8778\n          name: jolokia\n          protocol: TCP\n        - containerPort: 9090\n          name: jmx\n          protocol: TCP\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 3000\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20\n      - image: registry.internal.logz.io:5000/elasticsearch-openjdk:5.5.2-1\n        imagePullPolicy: Always\n        name: templates-validator-elasticsearch\n        ports:\n        - containerPort: 9200\n          name: esrest\n          protocol: TCP\n        - containerPort: 9300\n          name: estransport\n          protocol: TCP\n        env:\n        - name: ES_JAVA_OPTS\n          value: "-Xms768m -Xmx768m"\n        readinessProbe:\n          httpGet:\n            path: /_cluster/health\n            port: 9200\n          initialDelaySeconds: 60\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /_cluster/health\n            port: 9200\n          initialDelaySeconds: 60\n          periodSeconds: 20',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: templates-validator\n  name: templates-validator-service\nspec:\n  ports:\n  - nodePort: 30009\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: templates-validator\n  selector:\n    role: templates-validator\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: templates-validator-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: templates-validator-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: templates-validator-service\n          servicePort: 9990\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 15,
    name: 'insights-cms',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: insights-cms\n  name: insights-cms\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: insights-cms\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/insights-manager\n        imagePullPolicy: Always\n        name: insights-cms\n        resources:\n          requests:\n            cpu: 20m\n            memory: 1024Mi\n        ports:\n        - containerPort: 8080\n          name: web\n          protocol: TCP\n        env:\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: insights-cms\n  name: insights-cms-service\nspec:\n  ports:\n  - nodePort: 30010\n    port: 8080\n    protocol: TCP\n    targetPort: 8080\n    name: insights-cms\n  selector:\n    role: insights-cms\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: insights-cms-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: insights-cms-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: insights-cms-service\n          servicePort: 8080\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 16,
    name: 'lag-monitor',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: lag-monitor\n  name: lag-monitor\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: lag-monitor\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/lag-monitor\n        imagePullPolicy: Always\n        name: lag-monitor\n        resources:\n          requests:\n            cpu: 50m\n            memory: 1500Mi\n        ports:\n        - containerPort: 8778\n          name: jolokia\n          protocol: TCP\n        - containerPort: 9090\n          name: jmx\n          protocol: TCP\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 3001\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: lag-monitor\n  name: lag-monitor-service\nspec:\n  ports:\n  - nodePort: 30012\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: lag-monitor\n  selector:\n    role: lag-monitor\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: lag-monitor-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: lag-monitor-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: lag-monitor-service\n          servicePort: 9990\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 18,
    name: 'matcher-staging',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: matcher\n  name: matcher\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: matcher\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/insights-matcher\n        imagePullPolicy: Always\n        name: matcher\n        resources:\n          requests:\n            cpu: 50m\n            memory: 1024Mi\n        ports:\n        - containerPort: 8778\n          name: jolokia\n          protocol: TCP\n        - containerPort: 9090\n          name: jmx\n          protocol: TCP\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: KAFKA_MATCHER_TOPICS\n          value: "incoming-staging-1,incoming-staging-2"\n        - name: KAFKA_MATCHER_GROUP\n          value: "matcher-1"\n        - name: KAFKA_REBALANCE_MAX_RETRIES\n          value: "15"\n        - name: KAFKA_REBALANCE_BACKOFF_MILLIS\n          value: "20000"\n        readinessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 60\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 1',
    serviceYaml: null,
    ingressYaml: null,
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 19,
    name: 'app-no-limits',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: app\n  name: app\nspec:\n  replicas: 3\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 2\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: app\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/app\n        resources:\n          requests:\n            cpu: 100m\n            memory: 512Mi\n        command: ["sh", "-c", "cp -a /sites/app/public /work ; node server/server.js"]\n        volumeMounts:\n        - name: app-frontend-storage\n          mountPath: /work\n        imagePullPolicy: Always\n        name: app-node\n        ports:\n        - containerPort: 9000\n          protocol: TCP\n      - image: "registry.internal.logz.io:5000/frontend-nginx:c757f0e3a8104c661f3a29f1df287702346c0816"\n        command: ["sh", "-c", "echo \'127.0.0.1 app\' >> /etc/hosts ; nginx -g \'daemon off;\'"]\n        imagePullPolicy: Always\n        volumeMounts:\n        - name: app-frontend-storage\n          mountPath: /sites/app\n        imagePullPolicy: Always\n        name: app-nginx\n        resources:\n          requests:\n            cpu: 20m\n            memory: 64Mi\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        - containerPort: 80\n          protocol: TCP\n        readinessProbe:\n          httpGet:\n            path: /admin/utils/health-check\n            port: 8080\n          initialDelaySeconds: 90\n          periodSeconds: 10\n        livenessProbe:\n            httpGet:\n              path: /admin/utils/health-check\n              port: 8080\n            initialDelaySeconds: 90\n            periodSeconds: 20\n      volumes:\n      - name: app-frontend-storage\n        emptyDir: {}\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 60',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: app\n  name: app-service\nspec:  \n  ports:\n  - nodePort: 30002\n    name: nginx\n    port: 8080\n    protocol: TCP\n    targetPort: 8080\n  - nodePort: 30011\n    name: nginxredirect\n    port: 80\n    protocol: TCP\n    targetPort: 80\n  selector:\n    role: app\n  type: NodePort',
    ingressYaml: null,
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 20,
    name: 'snapshotter',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: snapshotter\n  name: snapshotter\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: snapshotter\n        apollo_jolokia_port: 9990\n    spec:\n      volumes:                          \n      - name: dshm\n        emptyDir:\n          medium: Memory\n      containers:\n      - image: registry.internal.logz.io:5000/snapshotter\n        imagePullPolicy: Always\n        name: snapshotter\n        resources:\n          requests:\n            cpu: 20m\n            memory: 3072Mi\n        ports:\n        - containerPort: 8778\n          name: jolokia\n          protocol: TCP\n        - containerPort: 9090\n          name: jmx\n          protocol: TCP\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 6000\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20\n      - image: registry.internal.logz.io:5000/selenium:3.12.0\n        imagePullPolicy: Always\n        name: snapshotter-selenium\n        ports:\n        - containerPort: 4444\n          name: selenium\n          protocol: TCP\n        volumeMounts:                 \n          - mountPath: /dev/shm\n            name: dshm\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: snapshotter\n  name: snapshotter-service\nspec:\n  ports:\n  - nodePort: 30013\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: snapshotter\n  selector:\n    role: snapshotter\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: snapshotter-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: snapshotter-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: snapshotter-service\n          servicePort: 9990\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 21,
    name: 'audit-indexer',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: audit-indexer\n  name: audit-indexer\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: audit-indexer\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/audit-indexer\n        imagePullPolicy: Always\n        name: audit-indexer\n        resources:\n          requests:\n            cpu: 50m\n            memory: 1536Mi\n        ports:\n        - containerPort: 8778\n          name: jolokia\n          protocol: TCP\n        - containerPort: 9090\n          name: jmx\n          protocol: TCP\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 3000\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 180\n          periodSeconds: 20',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: audit-indexer\n  name: audit-indexer-service\nspec:\n  ports:\n  - nodePort: 30014\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: audit-indexer\n  selector:\n    role: audit-indexer\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: audit-indexer-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: audit-indexer-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: audit-indexer-service\n          servicePort: 9990\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 22,
    name: 'auto-slow',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: auto-slow\n  name: auto-slow\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: auto-slow\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/auto-slow\n        imagePullPolicy: Always\n        name: auto-slow\n        resources:\n          requests:\n            cpu: 20m\n            memory: 1024Mi\n        ports:\n        - containerPort: 8778\n          name: jolokia\n          protocol: TCP\n        - containerPort: 9090\n          name: jmx\n          protocol: TCP\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 2000\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20',
    serviceYaml: null,
    ingressYaml: null,
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 23,
    name: 'adjuster',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: log-adjuster\n  name: log-adjuster\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: log-adjuster\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/log-adjuster\n        imagePullPolicy: Always\n        name: log-adjuster\n        resources:\n          requests:\n            cpu: 50m\n            memory: 1024Mi\n        ports:\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 3000\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 180\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 180\n          periodSeconds: 10',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: log-adjuster\n  name: log-adjuster-service\nspec:\n  ports:\n  - nodePort: 30016 \n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n  selector:\n    role: log-adjuster\n  type: NodePort\n',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: log-adjuster-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: log-adjuster-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: log-adjuster-service\n          servicePort: 9990\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 24,
    name: 'metrics-indexer',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata: \n  labels: \n    role: metrics-indexer\n  name: metrics-indexer\nspec: \n  replicas: 4\n  revisionHistoryLimit: 3\n  strategy: \n    rollingUpdate: \n      maxSurge: 20%\n      maxUnavailable: 0\n    type: RollingUpdate\n  template: \n    metadata: \n      labels: \n        apollo_jolokia_port: 9990\n        role: metrics-indexer\n    spec: \n      containers: \n        - \n          env: \n            - \n              name: EC2_NAME\n              valueFrom: \n                fieldRef: \n                  fieldPath: metadata.name\n            - \n              name: KUBE_POD_NAME\n              valueFrom: \n                fieldRef: \n                  fieldPath: metadata.name\n            - \n              name: KUBE_NAMESPACE\n              valueFrom: \n                fieldRef: \n                  fieldPath: metadata.namespace\n            - \n              name: OVERRIDE_MACHINE_MEMORY_MB\n              value: 3000\n            - \n              name: GROUP_NAME\n              value: {{ group_name }}\n            - \n              name: KHOST\n              value: {{ kafka_servers }}\n            - \n              name: GRAPHITE_SERVER\n              value: {{ graphite_host }}\n            - name: CONSUL\n          value: {{ consul_server }}\n          image: "registry.internal.logz.io:5000/metrics-indexer"\n          imagePullPolicy: Always\n          livenessProbe: \n            httpGet: \n              path: /system/health\n              port: 9990\n            initialDelaySeconds: 240\n            periodSeconds: 20\n          name: metrics-indexer\n          ports: \n            - \n              containerPort: 8778\n              name: jolokia\n              protocol: TCP\n            - \n              containerPort: 9090\n              name: jmx\n              protocol: TCP\n            - \n              containerPort: 9990\n              name: jersey\n              protocol: TCP\n          readinessProbe: \n            httpGet: \n              path: /system/ready\n              port: 9990\n            initialDelaySeconds: 240\n            periodSeconds: 20\n          resources: \n            requests: \n              cpu: 50m\n              memory: 2000Mi',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: metrics-indexer\n  name: metrics-indexer-service\nspec:\n  ports:\n  - nodePort: 30017\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: metrics-indexer\n  selector:\n    role: metrics-indexer\n  type: NodePort',
    ingressYaml: null,
    defaultShell: null,
    isPartOfGroup: true,
  },
  {
    id: 25,
    name: 'accounts-migrator',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: accounts-migrator\n  name: accounts-migrator\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: accounts-migrator\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/accounts-migrator\n        imagePullPolicy: Always\n        name: accounts-migrator\n        resources:\n          requests:\n            cpu: 50m\n            memory: 750Mi\n        ports:\n        - containerPort: 8778\n          name: jolokia\n          protocol: TCP\n        - containerPort: 9090\n          name: jmx\n          protocol: TCP\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 1500\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: accounts-migrator\n  name: accounts-migrator-service\nspec:\n  ports:\n  - nodePort: 30018\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: accounts-migrator\n  selector:\n    role: accounts-migrator\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: accounts-migrator-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: accounts-migrator-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: accounts-migrator-service\n          servicePort: 9990\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 26,
    name: 'configuration',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: configuration\n  name: configuration\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: configuration\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/configuration-service\n        imagePullPolicy: Always\n        name: configuration\n        resources:\n          requests:\n            cpu: 50m\n            memory: 1500Mi\n        ports:\n        - containerPort: 8778\n          name: jolokia\n          protocol: TCP\n        - containerPort: 9090\n          name: jmx\n          protocol: TCP\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 3001\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: configuration-service\n  name: configuration-service\nspec:\n  ports:\n  - nodePort: 30019\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: configuration-service\n  selector:\n    role: configuration\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: configuration-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: configuration-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: configuration-service\n          servicePort: 9990\n        path: /',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 27,
    name: 'insights-worker',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: insights-worker\n  name: insights-worker\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: insights-worker\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/insights-worker\n        imagePullPolicy: Always\n        name: insights-worker\n        resources:\n          requests:\n            cpu: 50m\n            memory: 750Mi\n        ports:\n        - containerPort: 8778\n          name: jolokia\n          protocol: TCP\n        - containerPort: 9090\n          name: jmx\n          protocol: TCP\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 1500\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 90\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 90\n          periodSeconds: 20',
    serviceYaml: null,
    ingressYaml: null,
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 28,
    name: 'insights',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: insights\n  name: insights\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: insights\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/insights-service\n        imagePullPolicy: Always\n        name: insights\n        resources:\n          requests:\n            cpu: 50m\n            memory: 1500Mi\n        ports:\n        - containerPort: 8778\n          name: jolokia\n          protocol: TCP\n        - containerPort: 9090\n          name: jmx\n          protocol: TCP\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 3001\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: insights-service\n  name: insights-service\nspec:\n  ports:\n  - nodePort: 30020\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: insights-service\n  selector:\n    role: insights\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: insights-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: insights-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: insights-service\n          servicePort: 9990\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 29,
    name: 'triggers',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: triggers\n  name: triggers\nspec:\n  replicas:  1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: triggers\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/triggers-service\n        imagePullPolicy: Always\n        name: triggers\n        resources:\n          requests:\n            cpu: 50m\n            memory: 3000Mi\n        ports:\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 4096\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: triggers-service\n  name: triggers-service\nspec:\n  ports:\n  - nodePort: 30021\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: triggers-service\n  selector:\n    role: triggers\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: triggers-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: triggers-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: triggers-service\n          servicePort: 9990\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 34,
    name: 'latency-monitor',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: latency-monitor\n  name: latency-monitor\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: latency-monitor\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/latency-monitor\n        imagePullPolicy: Always\n        name: latency-monitor\n        resources:\n          requests:\n            cpu: 50m\n            memory: 1500Mi\n        ports:\n        - containerPort: 8778\n          name: jolokia\n          protocol: TCP\n        - containerPort: 9090\n          name: jmx\n          protocol: TCP\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 3001\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: latency-monitor\n  name: latency-monitor\nspec:\n  ports:\n  - nodePort: 30023\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: latency-monitor\n  selector:\n    role: latency-monitor\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: latency-monitor-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: latency-monitor-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: latency-monitor\n          servicePort: 9990\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 35,
    name: 'zipkin-server',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: zipkin-server\n  name: zipkin-server\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: zipkin-server\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/logzio-zipkin:1.0.8\n        imagePullPolicy: Always\n        name: zipkin-server\n        resources:\n          requests:\n            cpu: 50m\n            memory: 1500Mi\n        ports:\n        - containerPort: 9411\n          name: zipkin\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 3000\n          \n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 9411\n          initialDelaySeconds: 120\n          periodSeconds: 60\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 9411\n          initialDelaySeconds: 120\n          periodSeconds: 20',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: zipkin-server\n  name: zipkin-server\nspec:\n  ports:\n  - nodePort: 30022\n    port: 9411\n    protocol: TCP\n    targetPort: 9411\n    name: zipkin-server\n  selector:\n    role: zipkin-server\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: zipkin-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: zipkin-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: zipkin-server\n          servicePort: 9411\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 38,
    name: 'archiver',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: archiver\n  name: archiver\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: archiver\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/archiver\n        imagePullPolicy: Always\n        name: archiver\n        resources:\n          requests:\n            cpu: 100m\n            memory: 1024Mi\n        lifecycle:\n          preStop:\n            exec:\n              command: ["/root/graceful_stop.bash", "--sync"]\n        ports:\n        - containerPort: 4000\n          name: from-logstash\n        - containerPort: 4020\n          name: to-logstash\n        - containerPort: 8778\n          name: jolokia\n          protocol: TCP\n        - containerPort: 9090\n          name: jmx\n          protocol: TCP\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: KAFKA_LE_ARCHIVE_TOPIC\n          value: {{ kafka_topic }}\n        - name: KAFKA_LE_ARCHIVE_GROUP\n          value: "archiving"\n        - name: BACKUP_READY_DIR\n          value: "\\\\/var\\\\/log\\\\/gaia\\\\/archiver\\\\/work\\\\/ready\\\\/"\n        - name: BACKUP_IN_PROGRESS_DIR\n          value: "\\\\/var\\\\/log\\\\/gaia\\\\/archiver\\\\/work\\\\/in-progress\\\\/"\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 120\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 120\n          periodSeconds: 10',
    serviceYaml: null,
    ingressYaml: null,
    defaultShell: null,
    isPartOfGroup: true,
  },
  {
    id: 41,
    name: 'auto-scaler',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: auto-scaler\n  name: auto-scaler\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: auto-scaler\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/auto-scaler\n        imagePullPolicy: Always\n        name: auto-scaler\n        resources:\n          requests:\n            cpu: 50m\n            memory: 1500Mi\n        ports:\n        - containerPort: 8778\n          name: jolokia\n          protocol: TCP\n        - containerPort: 9090\n          name: jmx\n          protocol: TCP\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 3001\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: auto-scaler\n  name: auto-scaler-service\nspec:\n  ports:\n  - nodePort: 30024\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: auto-scaler\n  selector:\n    role: auto-scaler\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: auto-scaler-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: auto-scaler-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: auto-scaler-service\n          servicePort: 9990\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 44,
    name: 'business-analytics',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: business-analytics\n  name: business-analytics\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: business-analytics\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/business-analytics\n        imagePullPolicy: Always\n        name: business-analytics\n        resources:\n          requests:\n            cpu: 50m\n            memory: 1500Mi\n        ports:\n        - containerPort: 8778\n          name: jolokia\n          protocol: TCP\n        - containerPort: 9090\n          name: jmx\n          protocol: TCP\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 3001\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20',
    serviceYaml: null,
    ingressYaml: null,
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 45,
    name: 'threats',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: threats\n  name: threats\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: threats\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/threats\n        imagePullPolicy: Always\n        name: threats\n        resources:\n          requests:\n            cpu: 50m\n            memory: 1500Mi\n        ports:\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 2048\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 120\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 120\n          periodSeconds: 20',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: threats\n  name: threats\nspec:\n  ports:\n  - nodePort: 30025\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: threats\n  selector:\n    role: threats\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: threats-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: threats-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: threats\n          servicePort: 9990\n        path: /',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 46,
    name: 'log-patterns-service',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: log-patterns-service\n  name: log-patterns-service\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: log-patterns-service\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/log-patterns-service\n        imagePullPolicy: Always\n        name: log-patterns-service\n        resources:\n          requests:\n            cpu: 50m\n            memory: 1500Mi\n        ports:\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 3000\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 180\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 180\n          periodSeconds: 20',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: log-patterns-service\n  name: log-patterns-service\nspec:\n  ports:\n  - nodePort: 30026\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: log-patterns-service\n  selector:\n    role: log-patterns-service\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: log-patterns-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: log-patterns-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: log-patterns-service\n          servicePort: 9990\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 47,
    name: 'pandora',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: pandora\n  name: pandora\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 0\n      maxUnavailable: 1\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: pandora\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/pandora\n        imagePullPolicy: Always\n        name: pandora\n        stdin: true\n        tty: true\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 5',
    serviceYaml: null,
    ingressYaml: null,
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 48,
    name: 'capacity-planner',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: capacity-planner\n  name: capacity-planner\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: capacity-planner\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/capacity-planner\n        imagePullPolicy: Always\n        name: capacity-planner\n        resources:\n          requests:\n            cpu: 50m\n            memory: 1500Mi\n        ports:\n        - containerPort: 8778\n          name: jolokia\n          protocol: TCP\n        - containerPort: 9090\n          name: jmx\n          protocol: TCP\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 3001\n        - name: CONSUL\n          value: {{ consul_server }}\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: capacity-planner-service\n  name: capacity-planner-service\nspec:\n  ports:\n  - nodePort: 30027\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: capacity-planner-service\n  selector:\n    role: capacity-planner\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: capacity-planner-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: capacity-planner-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: capacity-planner-service\n          servicePort: 9990\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 49,
    name: 'slack-integration',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: slack-integration\n  name: slack-integration\nspec:\n  replicas: 1\n  strategy:\n    rollingUpdate:\n      maxSurge: 0\n      maxUnavailable: 1\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: slack-integration\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/slack-integration\n        imagePullPolicy: Always\n        name: slack-integration\n        resources:\n          requests:\n            cpu: 100m\n            memory: 512Mi\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n        env:\n        - name: CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: slack-integration-config\n              key: client_id\n        - name: CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: slack-integration-config\n              key: client_secret\n        - name: VERIFICATION_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: slack-integration-config\n              key: verification_token\n        - name: EXTERNAL_DOMAIN\n          valueFrom:\n            secretKeyRef:\n              name: slack-integration-config\n              key: external_domain\n        - name: MYSQL_USER\n          valueFrom:\n            secretKeyRef:\n              name: slack-integration-config\n              key: mysql_user\n        - name: MYSQL_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: slack-integration-config\n              key: mysql_password\n        - name: MYSQL_DATABASE\n          valueFrom:\n            secretKeyRef:\n              name: slack-integration-config\n              key: mysql_database\n        - name: MYSQL_HOST\n          valueFrom:\n            secretKeyRef:\n              name: slack-integration-config\n              key: mysql_host\n        - name: LOGZIO_HOST\n          valueFrom:\n            secretKeyRef:\n              name: slack-integration-config\n              key: logzio_listener\n        - name: LOGZIO_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: slack-integration-config\n              key: logzio_token\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 8080\n          initialDelaySeconds: 60\n          periodSeconds: 15\n        livenessProbe:\n            httpGet:\n              path: /\n              port: 8080\n            initialDelaySeconds: 60\n            periodSeconds: 15\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 60\n',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: slack-integration\n  name: slack-integration\nspec:  \n  ports:\n  - nodePort: 30028\n    port: 8080\n    protocol: TCP\n    targetPort: 8080\n  selector:\n    role: slack-integration\n  type: NodePort\n',
    ingressYaml: null,
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 51,
    name: 'lookup-lists',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: lookup-lists\n  name: lookup-lists\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: lookup-lists\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/lookup-lists\n        imagePullPolicy: Always\n        name: lookup-lists\n        resources:\n          requests:\n            cpu: 50m\n            memory: 1500Mi\n        ports:\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 2048\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 120\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 120\n          periodSeconds: 20',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: lookup-lists\n  name: lookup-lists\nspec:\n  ports:\n  - nodePort: 30029\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: lookup-lists\n  selector:\n    role: lookup-lists\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: lookup-lists-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: lookup-lists-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: lookup-lists\n          servicePort: 9990\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 52,
    name: 'gatekeeper',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: gatekeeper\n  name: gatekeeper\nspec:\n  replicas: 2\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 2\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: gatekeeper\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/gatekeeper\n        imagePullPolicy: Always\n        name: gatekeeper\n        resources:\n          requests:\n            cpu: 50m\n            memory: 1500Mi\n        ports:\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 2048\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 10',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: gatekeeper\n  name: gatekeeper\nspec:\n  ports:\n  - nodePort: 30030\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: gatekeeper\n  selector:\n    role: gatekeeper\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: gatekeeper-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: gatekeeper-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: gatekeeper\n          servicePort: 9990\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 53,
    name: 'accounts',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n     role: accounts\n  name: accounts\nspec:\n  replicas: 2\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: accounts\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/accounts\n        imagePullPolicy: Always\n        name: accounts\n        resources:\n          requests:\n            cpu: 50m\n            memory: 1500Mi\n        ports:\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 2048\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 120\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 120\n          periodSeconds: 10',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: accounts\n  name: accounts\nspec:\n  ports:\n  - nodePort: 30031\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: accounts\n  selector:\n    role: accounts\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: accounts-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: accounts-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: accounts\n          servicePort: 9990\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 55,
    name: 'metrics-service',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: metrics-service\n  name: metrics-service\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: metrics-service\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/metrics-service\n        imagePullPolicy: Always\n        name: metrics-service\n        resources:\n          requests:\n            cpu: 50m\n            memory: 1024Mi\n        ports:\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 2048\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 90\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 120\n          periodSeconds: 15',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: metrics-service\n  name: metrics-service\nspec:\n  ports:\n  - nodePort: 30033\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: metrics-service\n  selector:\n    role: metrics-service\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: metrics-service-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: metrics-service-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: metrics-service\n          servicePort: 9990\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 57,
    name: 'rollup-service',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: rollup-service\n  name: rollup-service\nspec:\n  replicas: 5\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: rollup-service\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/rollup-service\n        imagePullPolicy: Always\n        name: rollup-service\n        resources:\n          requests:\n            cpu: 50m\n            memory: 9000Mi\n        ports:\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 16000\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 120\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 120\n          periodSeconds: 10\n      nodeSelector:\n        {{rollup_enabled}}\n      tolerations:\n      - key: "dedicated"\n        value: "rollup"          ',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: rollup-service\n  name: rollup-service\nspec:\n  ports:\n  - nodePort: 30035\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: rollup-service\n  selector:\n    role: rollup-service\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: rollup-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: rollup-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: rollup-service\n          servicePort: 9990\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 59,
    name: 'restorer',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: restorer\n  name: restorer\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: restorer\n        apollo_jolokia_port: 9990\n    spec:\n      volumes:                          \n      - name: dshm\n        emptyDir:\n          medium: Memory\n      containers:\n      - image: registry.internal.logz.io:5000/restorer\n        imagePullPolicy: Always\n        name: restorer\n        resources:\n          requests:\n            cpu: 20m\n            memory: 3072Mi\n        ports:\n        - containerPort: 8778\n          name: jolokia\n          protocol: TCP\n        - containerPort: 9090\n          name: jmx\n          protocol: TCP\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 6000\n        - name: KHOST\n          value: {{ kafka_servers }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 90\n          periodSeconds: 30\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 90\n          periodSeconds: 30',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: restorer\n  name: restorer-service\nspec:\n  ports:\n  - nodePort: 30036\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: restorer\n  selector:\n    role: restorer\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: restorer-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: restorer-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: restorer-service\n          servicePort: 9990\n        path: /',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 60,
    name: 'kibana-6',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata: \n  labels: \n    role: kibana-6\n  name: kibana-6\nspec: \n  replicas: 3\n  revisionHistoryLimit: 3\n  strategy: \n    rollingUpdate: \n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template: \n    metadata: \n      labels: \n        role: kibana-6\n    spec: \n      containers: \n        - \n          command: \n            - node\n            - src/cli\n          image: "registry.internal.logz.io:5000/kibana"\n          imagePullPolicy: Always\n          livenessProbe: \n            httpGet: \n              path: /api/logz/status/healthiness\n              port: 5601\n            initialDelaySeconds: 40\n            periodSeconds: 15\n            failureThreshold: 3\n          name: kibana-6-node\n          ports: \n            - \n              containerPort: 5601\n              protocol: TCP\n          readinessProbe: \n            httpGet: \n              path: /api/logz/status/readiness\n              port: 5601\n            initialDelaySeconds: 40\n            periodSeconds: 1\n            failureThreshold: 1\n          resources: \n            requests: \n              cpu: 100m\n              memory: 512Mi\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 0',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: kibana-6\n  name: kibana-6-service\nspec:  \n  ports:\n  - port: 5601\n    protocol: TCP\n    targetPort: 5601\n  selector:\n    role: kibana-6\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: kibana-6-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: kibana-6-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: kibana-6-service\n          servicePort: 5601\n        path: /\n',
    defaultShell: '/bin/sh',
    isPartOfGroup: false,
  },
  {
    id: 61,
    name: 'grafana',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata: \n  labels: \n    role: grafana\n  name: grafana\nspec: \n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy: \n    rollingUpdate: \n      maxSurge: 0\n      maxUnavailable: 2\n    type: RollingUpdate\n  template: \n    metadata: \n      labels: \n        role: grafana\n    spec: \n      containers: \n        - \n          command: \n            - /run.sh\n          image: "registry.internal.logz.io:5000/grafana"\n          imagePullPolicy: Always\n          name: grafana-node\n          ports: \n            - \n              containerPort: 3000\n              protocol: TCP\n          env:\n            - name: EC2_NAME\n              valueFrom:\n                fieldRef:\n                  fieldPath: metadata.name\n            - name: KUBE_POD_NAME\n              valueFrom:\n                fieldRef:\n                  fieldPath: metadata.name\n            - name: KUBE_NAMESPACE\n              valueFrom:\n                fieldRef:\n                  fieldPath: metadata.namespace\n            - name: GF_SESSION_PROVIDER\n              value: {{ gf_session_provider }}\n            - name: GF_SESSION_PROVIDER_CONFIG\n              value: {{ gf_session_provider_config }}\n            - name: GF_DATABASE_URL\n              value: {{ gf_database_url }}\n            - name: GF_DATABASE_TYPE\n              value: {{ gf_database_type }}\n            - name: GF_DATABASE_HOST\n              value: {{ gf_database_host }}\n            - name: GF_DATABASE_NAME\n              value: {{ gf_database_name }}\n            - name: GF_DATABASE_USER\n              value: {{ gf_database_user }}\n            - name: GF_DATABASE_PASSWORD\n              value: {{ gf_database_password }}\n            - name: GF_SECURITY_ADMIN_ACCOUNT\n              value: {{ gf_security_admin_account }}\n            - name: GF_SECURITY_DATA_SOURCE_PROXY_WHITELIST\n              value: {{ gf_security_data_source_proxy_whitelist }}\n            - name: GF_USERS_DEFAULT_THEME\n              value: {{ gf_users_default_theme }}\n            - name: GF_USERS_ALLOW_SIGN_UP\n              value: {{ gf_users_allow_sign_up }}\n            - name: GF_AUTH_PROXY_AUTO_SIGN_UP\n              value: {{ gf_auth_proxy_auto_sign_up }}\n            - name: GF_ALERTING_ENABLED\n              value: {{ gf_alerting_enabled }}\n            - name: GF_ALERTING_EXECUTE_ALERTS\n              value: {{ gf_alerting_execute_alerts }}\n          resources: \n            requests: \n              cpu: 100m\n              memory: 512Mi\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 0\n',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: grafana\n  name: grafana-service\nspec:  \n  ports:\n  - nodePort: 30039\n    port: 3000\n    protocol: TCP\n    targetPort: 3000\n    name: grafana-service\n  selector:\n    role: grafana\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: grafana-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: grafana-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: grafana-service\n          servicePort: 3000\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: true,
  },
  {
    id: 63,
    name: 'grafana-sync',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: grafana-sync\n  name: grafana-sync\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: grafana-sync\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/grafana-sync\n        imagePullPolicy: Always\n        name: grafana-sync\n        resources:\n          requests:\n            cpu: 50m\n            memory: 1024Mi\n        ports:\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 2048\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 10',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: grafana-sync\n  name: grafana-sync\nspec:\n  ports:\n  - nodePort: 30037\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: grafana-sync\n  selector:\n    role: grafana-sync\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: grafana-sync-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: grafana-sync-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: grafana-sync\n          servicePort: 9990\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 64,
    name: 'demo-livetail-logs',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: demo-livetail-logs\n  name: demo-livetail-logs\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 0\n      maxUnavailable: 1\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: demo-livetail-logs\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/logzio-demo-livetail-logs:1.0.4\n        imagePullPolicy: Always\n        name: demo-livetail-logs\n        stdin: true\n        tty: true\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 5',
    serviceYaml: null,
    ingressYaml: null,
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 65,
    name: 'query-service',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: query-service\n  name: query-service\nspec:\n  replicas: 5\n  revisionHistoryLimit: 5\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: query-service\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/query-service\n        imagePullPolicy: Always\n        name: query-service\n        resources:\n          requests:\n            cpu: 50m\n            memory: 3000Mi\n        ports:\n        - containerPort: 8778\n          name: jolokia\n          protocol: TCP\n        - containerPort: 9090\n          name: jmx\n          protocol: TCP\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 6192\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 180\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 180\n          periodSeconds: 20',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: query-service\n  name: query-service\nspec:\n  ports:\n  - nodePort: 30040\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: query-service\n  selector:\n    role: query-service\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: query-service-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: query-service-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: query-service\n          servicePort: 9990\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 69,
    name: 'stacktrace-js',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata: \n  labels: \n    role: stacktrace-js\n  name: stacktrace-js\nspec: \n  replicas: 2\n  revisionHistoryLimit: 3\n  strategy: \n    rollingUpdate: \n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template: \n    metadata: \n      labels: \n        role: stacktrace-js\n    spec: \n      containers: \n        - \n          command: \n            - node\n            - index\n          image: "registry.internal.logz.io:5000/stacktrace-js"\n          imagePullPolicy: Always\n          name: stacktrace-js-node\n          ports: \n            - \n              containerPort: 5588\n              protocol: TCP\n          resources: \n            requests: \n              cpu: 100m\n              memory: 512Mi\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 0',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: stacktrace-js\n  name: stacktrace-js-service\nspec:  \n  ports:\n  - port: 5588\n    protocol: TCP\n    targetPort: 5588\n  selector:\n    role: stacktrace-js\n  type: NodePort',
    ingressYaml: null,
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 70,
    name: 'metrics-ingester',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata: \n  labels: \n    role: metrics-ingester\n  name: metrics-ingester\nspec: \n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy: \n    rollingUpdate: \n      maxSurge: 20%\n      maxUnavailable: 0\n    type: RollingUpdate\n  template: \n    metadata: \n      labels: \n        apollo_jolokia_port: 9990\n        role: metrics-ingester\n    spec: \n      nodeSelector:\n        {{az_label}} {{metrics_ingester_az}}  \n      containers: \n        - env: \n            - name: EC2_NAME\n              valueFrom: \n                fieldRef: \n                  fieldPath: metadata.name\n            - name: KUBE_POD_NAME\n              valueFrom: \n                fieldRef: \n                  fieldPath: metadata.name\n            - name: KUBE_NAMESPACE\n              valueFrom: \n                fieldRef: \n                  fieldPath: metadata.namespace\n            - name: OVERRIDE_MACHINE_MEMORY_MB\n              value: 3000\n            - name: KAFKA_TOPIC\n              value: {{ kafka_topic }}\n            - name: KAFKA_GROUP\n              value: {{ kafka_group }}\n            - name: KHOST\n              value: {{ kafka_servers }}\n            - name: GRAPHITE_SERVER\n              value: {{ graphite_host }}\n            - name: CONSUL\n          value: {{ consul_server }}\n          image: "registry.internal.logz.io:5000/metrics-ingester"\n          imagePullPolicy: Always\n          livenessProbe: \n            httpGet: \n              path: /system/health\n              port: 9990\n            initialDelaySeconds: 90\n            periodSeconds: 20\n          name: metrics-ingester\n          ports: \n            - \n              containerPort: 8778\n              name: jolokia\n              protocol: TCP\n            - \n              containerPort: 9090\n              name: jmx\n              protocol: TCP\n            - \n              containerPort: 9990\n              name: jersey\n              protocol: TCP\n          readinessProbe: \n            httpGet: \n              path: /system/ready\n              port: 9990\n            initialDelaySeconds: 90\n            periodSeconds: 20\n          resources: \n            requests: \n              cpu: 50m\n              memory: 2000Mi',
    serviceYaml: null,
    ingressYaml: null,
    defaultShell: null,
    isPartOfGroup: true,
  },
  {
    id: 72,
    name: 'security-demo-sender',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: security-demo-sender\n  name: security-demo-sender\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: security-demo-sender\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/build-docker-security-demo-sender:latest\n        imagePullPolicy: Always\n        name: security-demo-sender\n        args: ["http://listener.logz.io:8070",\n            "TwutWwTfgalxmKoFJxvNPuxKRnDnPRTx"]\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 5',
    serviceYaml: null,
    ingressYaml: null,
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 81,
    name: 'healthcheck',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: healthcheck\n  name: healthcheck\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: healthcheck\n    spec:\n      containers:\n        -\n          image: "registry.internal.logz.io:5000/healthcheck"\n          imagePullPolicy: Always\n          name: healthcheck-node\n          ports:\n            -\n              containerPort: 2233\n              protocol: TCP\n          livenessProbe:\n            httpGet:\n              path: /healthiness\n              port: 2233\n            initialDelaySeconds: 10\n            periodSeconds: 10\n            failureThreshold: 3\n          readinessProbe:\n            httpGet:\n              path: /readiness\n              port: 2233\n            initialDelaySeconds: 10\n            periodSeconds: 1\n            failureThreshold: 1\n          resources:\n            requests:\n              cpu: 100m\n              memory: 512Mi\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 0',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata: \n  labels: \n    role: healthcheck\n  name: healthcheck-service\nspec: \n  ports: \n    - \n      nodePort: 30044\n      port: 2233\n      protocol: TCP\n      targetPort: 2233\n  selector: \n    role: healthcheck\n  type: NodePort',
    ingressYaml: null,
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 82,
    name: 'noisy-manager',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: noisy-manager\n  name: noisy-manager\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 0\n      maxUnavailable: 1\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: noisy-manager\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/logzio-noisy-manager\n        imagePullPolicy: Always\n        name: noisy-manager\n        stdin: true\n        tty: true\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 5',
    serviceYaml: null,
    ingressYaml: null,
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 83,
    name: 'self-service',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: self-service\n  name: self-service\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: self-service\n        apollo_jolokia_port: 9990\n    spec:\n      volumes:                          \n      - name: dshm\n        emptyDir:\n          medium: Memory\n      containers:\n      - image: registry.internal.logz.io:5000/self-service\n        imagePullPolicy: Always\n        name: self-service\n        resources:\n          requests:\n            cpu: 20m\n            memory: 3072Mi\n        ports:\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 3072\n        - name: KHOST\n          value: {{ kafka_servers }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 20',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: self-service\n  name: self-service-service\nspec:\n  ports:\n  - nodePort: 30034\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: self-service\n  selector:\n    role: self-service\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: self-service-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: self-service-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: self-service-service\n          servicePort: 9990\n        path: /',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 84,
    name: 'app-frontend',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: app-frontend\n  name: app-frontend\nspec:\n  replicas: 2\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: app-frontend\n    spec:\n      containers:\n      - image: "registry.internal.logz.io:5000/app-frontend"\n        imagePullPolicy: Always\n        name: app-frontend\n        ports:\n        - containerPort: 7070\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 512Mi\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 7070\n          initialDelaySeconds: 3\n          periodSeconds: 3',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: app-frontend\n  name: app-frontend\nspec:  \n  ports:\n  - nodePort: 30042\n    port: 7070\n    protocol: TCP\n  selector:\n    role: app-frontend\n  type: NodePort',
    ingressYaml: null,
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 86,
    name: 'haystack-ui',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata: \n  labels: \n    role: haystack-ui\n  name: haystack-ui\nspec: \n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy: \n    rollingUpdate: \n      maxSurge: 0\n      maxUnavailable: 1\n    type: RollingUpdate\n  template: \n    metadata: \n      labels: \n        role: haystack-ui\n    spec: \n      containers: \n        - image: "registry.internal.logz.io:5000/logzio-haystack-ui:1.1.6"\n          imagePullPolicy: Always\n          name: haystack-ui\n          resources: \n            requests: \n              cpu: 100m\n              memory: 100Mi\n          ports: \n            - containerPort: 8080\n              name: ui\n              protocol: TCP',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: haystack-ui\n  name: haystack-ui\nspec:  \n  ports:\n  - nodePort: 31008\n    port: 8080\n    protocol: TCP\n    targetPort: 8080\n    name: haystack-ui\n  selector:\n    role: haystack-ui\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: haystack-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: haystack-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: haystack-ui\n          servicePort: 8080\n        path: /',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 87,
    name: 'reports-engine',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: reports-engine\n  name: reports-engine\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: reports-engine\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/reports-engine\n        imagePullPolicy: Always\n        name: reports-engine\n        resources:\n          requests:\n            cpu: 50m\n            memory: 1500Mi\n        ports:\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 2048\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 10',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: reports-engine\n  name: reports-engine\nspec:\n  ports:\n  - nodePort: 30045\n    port: 9990\n    protocol: TCP\n    targetPort: 9990\n    name: reports-engine\n  selector:\n    role: reports-engine\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: reports-engine-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: reports-engine-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: reports-engine\n          servicePort: 9990\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 88,
    name: 'api-gateway',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: api-gateway\n    gatewayType: {{ gatewayType }}\n  name: api-gateway\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: api-gateway\n        gatewayType: {{ gatewayType }}\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/api-gateway\n        imagePullPolicy: Always\n        name: api-gateway\n        resources:\n          requests:\n            cpu: 50m\n            memory: 2048Mi\n        ports:\n        - containerPort: 8080\n          name: traffic\n          protocol: TCP\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 2048\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 10',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: api-gateway\n  name: api-gateway\nspec:\n  ports:\n  - nodePort: 30048\n    port: 8080\n    protocol: TCP\n    targetPort: 8080\n    name: api-gateway\n  selector:\n    role: api-gateway\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: api-gateway-app-{{ environment }}-{{ region }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: api-gateway-app-{{ environment }}-{{ region }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: api-gateway\n          servicePort: 8080\n        path: /',
    defaultShell: null,
    isPartOfGroup: true,
  },
  {
    id: 89,
    name: 'tagging-monitor',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: tagging-monitor\n  name: tagging-monitor\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: tagging-monitor\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/tagging-monitor\n        imagePullPolicy: Always\n        name: tagging-monitor\n        resources:\n          requests:\n            cpu: 50m\n            memory: 2048Mi\n        ports:\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 2048\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 60\n          periodSeconds: 10',
    serviceYaml: null,
    ingressYaml: null,
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 91,
    name: 'metrics-index-failures',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: metrics-index-failures\n  name: metrics-index-failures\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: metrics-index-failures\n        apollo_jolokia_port: 9990\n    spec:\n      containers:\n      - image: registry.internal.logz.io:5000/metrics-index-failures\n        imagePullPolicy: Always\n        name: metrics-index-failures\n        resources:\n          requests:\n            cpu: 50m\n            memory: 1024Mi\n        ports:\n        - containerPort: 9990\n          name: jersey\n          protocol: TCP\n        env:\n        - name: EC2_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: KUBE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: OVERRIDE_MACHINE_MEMORY_MB\n          value: 2048\n        - name: KHOST\n          value: {{ kafka_servers }}\n        - name: GRAPHITE_SERVER\n          value: {{ graphite_host }}\n        - name: CONSUL\n          value: {{ consul_server }}\n        readinessProbe:\n          httpGet:\n            path: /system/ready\n            port: 9990\n          initialDelaySeconds: 90\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /system/health\n            port: 9990\n          initialDelaySeconds: 120\n          periodSeconds: 15',
    serviceYaml: null,
    ingressYaml: null,
    defaultShell: null,
    isPartOfGroup: false,
  },
  {
    id: 92,
    name: 'app-styleguide',
    deploymentYaml:
      'apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    role: app-styleguide\n  name: app-styleguide\nspec:\n  replicas: 1\n  revisionHistoryLimit: 3\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        role: app-styleguide\n    spec:\n      containers:\n      - image: "registry.internal.logz.io:5000/app-storybook"\n        imagePullPolicy: Always\n        name: app-styleguide\n        ports:\n        - containerPort: 7071\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 100m\n            memory: 512Mi\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 7071\n          initialDelaySeconds: 3\n          periodSeconds: 3',
    serviceYaml:
      'apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    role: app-styleguide\n  name: app-styleguide\nspec:  \n  ports:\n  - nodePort: 30049\n    port: 7071\n    protocol: TCP\n  selector:\n    role: app-styleguide\n  type: NodePort',
    ingressYaml:
      'apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: styleguide-{{ environment }}-ingress\n  annotations:\n    kubernetes.io/ingress.class: "nginx"\nspec:\n  rules:\n  - host: styleguide-{{ environment }}.internal.logz.io\n    http:\n      paths:\n      - backend:\n          serviceName: app-styleguide\n          servicePort: 7071\n        path: /\n',
    defaultShell: null,
    isPartOfGroup: false,
  },
];

export const stackServicesMock = [{"id":4,"name":"Web App","stackType":"SERVICES","services":[3,60,69,84],"enabled":true},{"id":5,"name":"All gaia-full servicesMock","stackType":"SERVICES","services":[6,7,12,14,16,20,21,22,23,25,26,27,28,29,34,41,44,45,46,48,51,52,53,55,57,59,63,65,88],"enabled":true}];

export const envMock =[{"id":2,"name":"logzio-staging-us-east-1","geoRegion":"us-east-1","availability":"STAGING","kubernetesMaster":"https://k8s-2-staging-us-east-1.internal.logz.io:6443","kubernetesToken":"******","kubernetesCaCert":null,"kubernetesNamespace":"staging","servicePortCoefficient":0,"requireDeploymentMessage":false,"requireHealthCheck":false,"concurrencyLimit":-1,"additionalParams":"{\"type\": \"NodePort\", \"nodePortNginx\": \"nodePort: 30002\", \"nodePortNginxredirect\": \"nodePort: 30011\", \"nodePortHttps\": \"nodePort: 30007\", \"nodePortEngine\": \"nodePort: 30008\", \"az_label\": \"logzio/az:\", \"kafka_servers\": \"staging-us-east-1-kafka-1-broker-1003.internal.logz.io:9092,staging-us-east-1-kafka-1-broker-1004.internal.logz.io:9092\", \"consul_server\": \"consul-staging-us-east-1.internal.logz.io\", \"salt_extra\": \"--idle\"}"},{"id":4,"name":"logzio-preproduction-us-east-1","geoRegion":"us-east-1","availability":"PREPRODUCTION","kubernetesMaster":"https://k8s-2-staging-us-east-1.internal.logz.io:6443","kubernetesToken":"******","kubernetesCaCert":null,"kubernetesNamespace":"preproduction","servicePortCoefficient":600,"requireDeploymentMessage":false,"requireHealthCheck":false,"concurrencyLimit":-1,"additionalParams":"{\"type\": \"NodePort\", \"nodePortNginx\": \"nodePort: 30002\", \"nodePortNginxredirect\": \"nodePort: 30011\", \"az_label\": \"logzio/az:\", \"kafka_servers\": \"staging-us-east-1-kafka-1-broker-1003.internal.logz.io:9092,staging-us-east-1-kafka-1-broker-1004.internal.logz.io:9092\", \"consul_server\": \"consul-staging-us-east-1.internal.logz.io\", \"salt_extra\": \"--idle\"}"},{"id":5,"name":"logzio-prod-us-east-1","geoRegion":"us-east-1","availability":"PROD","kubernetesMaster":"https://k8s-1-prod-us-east-1.internal.logz.io:6443","kubernetesToken":"******","kubernetesCaCert":null,"kubernetesNamespace":"prod","servicePortCoefficient":0,"requireDeploymentMessage":true,"requireHealthCheck":true,"concurrencyLimit":-1,"additionalParams":"{\"type\": \"NodePort\", \"nodePortNginx\": \"nodePort: 30002\", \"nodePortNginxredirect\": \"nodePort: 30011\", \"nodePortHttps\": \"nodePort: 30007\", \"nodePortEngine\": \"nodePort: 30008\", \"az_label\": \"logzio/az:\", \"kafka_servers\": \"PROD-kafka-1-i-e00f317d.servers.us-east-1.internal.logz.io:9092,PROD-kafka10-1-i-0abda0e1a9c29f715.servers.us-east-1.internal.logz.io:9092,PROD-kafka10-1-i-030357de1466f029f.servers.us-east-1.internal.logz.io:9092,PROD-kafka10-1-i-0374261842751eb23.servers.us-east-1.internal.logz.io:9092,PROD-kafka10-1-i-0cdc4c3284e19803d.servers.us-east-1.internal.logz.io:9092\", \"graphite_host\": \"graphite.internal.logz.io\", \"consul_server\": \"consul-prod-us-east-1.internal.logz.io\", \"salt_extra\": \"\", \"scanners_enabled\": \"scanners: enabled\", \"rollup_enabled\": \"rollup: enabled\"}"},{"id":6,"name":"logzio-prod-kibana5-us-east-1","geoRegion":"us-east-1","availability":"PROD","kubernetesMaster":"https://k8s-1-prod-us-east-1.internal.logz.io:6443","kubernetesToken":"******","kubernetesCaCert":null,"kubernetesNamespace":"prodkibana5","servicePortCoefficient":300,"requireDeploymentMessage":false,"requireHealthCheck":false,"concurrencyLimit":-1,"additionalParams":"{\"type\": \"NodePort\", \"nodePortNginx\": \"nodePort: 30002\", \"nodePortNginxredirect\": \"nodePort: 30011\", \"az_label\": \"logzio/az:\", \"kafka_servers\": \"PROD-kafka-1-i-e00f317d.servers.us-east-1.internal.logz.io:9092,PROD-kafka10-1-i-0abda0e1a9c29f715.servers.us-east-1.internal.logz.io:9092,PROD-kafka10-1-i-030357de1466f029f.servers.us-east-1.internal.logz.io:9092,PROD-kafka10-1-i-0374261842751eb23.servers.us-east-1.internal.logz.io:9092,PROD-kafka10-1-i-0cdc4c3284e19803d.servers.us-east-1.internal.logz.io:9092\", \"graphite_host\": \"graphite.internal.logz.io\", \"consul_server\": \"consul.internal.logz.io:8500\", \"salt_extra\": \"--idle\"}"},{"id":7,"name":"logzio-staging-eu-central-1","geoRegion":"eu-central-1","availability":"STAGING","kubernetesMaster":"https://k8s-1-staging-eu-central-1.internal.logz.io:6443","kubernetesToken":"******","kubernetesCaCert":null,"kubernetesNamespace":"staging","servicePortCoefficient":0,"requireDeploymentMessage":false,"requireHealthCheck":false,"concurrencyLimit":-1,"additionalParams":"{\"type\": \"NodePort\", \"nodePortNginx\": \"nodePort: 30002\", \"nodePortNginxredirect\": \"nodePort: 30011\", \"nodePortHttps\": \"nodePort: 30007\", \"nodePortEngine\": \"nodePort: 30008\", \"az_label\": \"logzio/az:\", \"kafka_servers\": \"staging-eu-central-1-kafka-1-broker-1001.internal.logz.io:9092\", \"consul_server\": \"consul-prod-us-east-1.internal.logz.io\", \"salt_extra\": \"--idle\"}"},{"id":9,"name":"logzio-prod-eu-central-1","geoRegion":"eu-central-1","availability":"PROD","kubernetesMaster":"https://k8s-1-prod-eu-central-1.internal.logz.io:6443","kubernetesToken":"******","kubernetesCaCert":null,"kubernetesNamespace":"prod","servicePortCoefficient":0,"requireDeploymentMessage":true,"requireHealthCheck":true,"concurrencyLimit":-1,"additionalParams":"{\"type\": \"NodePort\", \"nodePortNginx\": \"nodePort: 30002\", \"nodePortNginxredirect\": \"nodePort: 30011\", \"nodePortHttps\": \"nodePort: 30007\", \"nodePortEngine\": \"nodePort: 30008\", \"az_label\": \"logzio/az:\", \"kafka_servers\": \"PROD-kafka-1-i-e00f317d.servers.us-east-1.internal.logz.io:9092,PROD-kafka10-1-i-0abda0e1a9c29f715.servers.us-east-1.internal.logz.io:9092,PROD-kafka10-1-i-030357de1466f029f.servers.us-east-1.internal.logz.io:9092,PROD-kafka10-1-i-0374261842751eb23.servers.us-east-1.internal.logz.io:9092,PROD-kafka10-1-i-0cdc4c3284e19803d.servers.us-east-1.internal.logz.io:9092\", \"graphite_host\": \"graphite.internal.logz.io\", \"consul_server\": \"consul.internal.logz.io:8500\", \"salt_extra\": \"--idle\", \"scanners_enabled\": \"scanners: enabled\"}"},{"id":51,"name":"logzio-prod-le-us-east-1","geoRegion":"us-east-1","availability":"PROD","kubernetesMaster":"https://k8s-2-prod-us-east-1.internal.logz.io:6443","kubernetesToken":"******","kubernetesCaCert":null,"kubernetesNamespace":"prod","servicePortCoefficient":0,"requireDeploymentMessage":true,"requireHealthCheck":true,"concurrencyLimit":1,"additionalParams":"{\"type\": \"NodePort\", \"nodePortNginx\": \"nodePort: 30002\", \"nodePortNginxredirect\": \"nodePort: 30011\", \"az_label\": \"logzio/az:\", \"kafka_servers\": \"PROD-kafka-1-i-e00f317d.servers.us-east-1.internal.logz.io:9092,PROD-kafka10-1-i-0abda0e1a9c29f715.servers.us-east-1.internal.logz.io:9092,PROD-kafka10-1-i-030357de1466f029f.servers.us-east-1.internal.logz.io:9092,PROD-kafka10-1-i-0374261842751eb23.servers.us-east-1.internal.logz.io:9092,PROD-kafka10-1-i-0cdc4c3284e19803d.servers.us-east-1.internal.logz.io:9092\", \"graphite_host\": \"graphite.internal.logz.io\", \"consul_server\": \"consul-prod-us-east-1.internal.logz.io\", \"salt_extra\": \"--idle\"}"},{"id":52,"name":"logzio-prod-le-eu-central-1","geoRegion":"eu-central-1","availability":"PROD","kubernetesMaster":"https://k8s-2-prod-eu-central-1.internal.logz.io:6443","kubernetesToken":"******","kubernetesCaCert":null,"kubernetesNamespace":"prod","servicePortCoefficient":0,"requireDeploymentMessage":true,"requireHealthCheck":true,"concurrencyLimit":1,"additionalParams":"{\"type\": \"NodePort\", \"nodePortNginx\": \"nodePort: 30002\", \"nodePortNginxredirect\": \"nodePort: 30011\", \"az_label\": \"logzio/az:\", \"kafka_servers\": \"PROD-kafka-1-i-e00f317d.servers.us-east-1.internal.logz.io:9092,PROD-kafka10-1-i-0abda0e1a9c29f715.servers.us-east-1.internal.logz.io:9092,PROD-kafka10-1-i-030357de1466f029f.servers.us-east-1.internal.logz.io:9092,PROD-kafka10-1-i-0374261842751eb23.servers.us-east-1.internal.logz.io:9092,PROD-kafka10-1-i-0cdc4c3284e19803d.servers.us-east-1.internal.logz.io:9092\", \"graphite_host\": \"graphite.internal.logz.io\", \"consul_server\": \"consul.internal.logz.io:8500\", \"salt_extra\": \"--idle\"}"},{"id":58,"name":"logzio-prod-westeurope-services","geoRegion":"westeurope","availability":"PROD","kubernetesMaster":"https://logzio-westeurope-prod-aks-1-services-2a77397a.hcp.westeurope.azmk8s.io","kubernetesToken":"******","kubernetesCaCert":"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","kubernetesNamespace":"prod","servicePortCoefficient":0,"requireDeploymentMessage":true,"requireHealthCheck":true,"concurrencyLimit":-1,"additionalParams":"{\"type\": \"LoadBalancer\", \"annotations\": \"annotations:\", \"internalLB\":\"service.beta.kubernetes.io/azure-load-balancer-internal: \\\"true\\\"\", \"kafka_servers\": \"prod-westeurope-kafka-1-broker-1001.internal.logz.io:9092,prod-westeurope-kafka-1-broker-1002.internal.logz.io:9092,prod-westeurope-kafka-1-broker-1003.internal.logz.io:9092\", \"graphite_host\": \"graphite.prod.westeurope.internal.logz.io\", \"consul_server\": \"consul-prod-us-east-1.internal.logz.io\", \"salt_extra\": \"--idle\"}"},{"id":59,"name":"logzio-prod-westeurope-le","geoRegion":"westeurope","availability":"PROD","kubernetesMaster":"https://logzio-westeurope-prod-aks-2-logengines-75bc4237.hcp.westeurope.azmk8s.io","kubernetesToken":"******","kubernetesCaCert":"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","kubernetesNamespace":"prod","servicePortCoefficient":0,"requireDeploymentMessage":true,"requireHealthCheck":true,"concurrencyLimit":-1,"additionalParams":"{\"type\": \"LoadBalancer\", \"annotations\": \"annotations:\", \"internalLB\":\"service.beta.kubernetes.io/azure-load-balancer-internal: \\\"true\\\"\", \"kafka_servers\": \"prod-westeurope-kafka-1-broker-1001.internal.logz.io:9092,prod-westeurope-kafka-1-broker-1002.internal.logz.io:9092,prod-westeurope-kafka-1-broker-1003.internal.logz.io:9092\", \"graphite_host\": \"graphite.prod.westeurope.internal.logz.io\", \"consul_server\": \"consul-prod-us-east-1.internal.logz.io\", \"salt_extra\": \"--idle\"}"},{"id":60,"name":"logzio-prod-westeurope-scanners","geoRegion":"westeurope","availability":"PROD","kubernetesMaster":"https://logzio-westeurope-prod-aks-4-scanners-721d9ba1.hcp.westeurope.azmk8s.io","kubernetesToken":"******","kubernetesCaCert":"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","kubernetesNamespace":"prod","servicePortCoefficient":0,"requireDeploymentMessage":true,"requireHealthCheck":true,"concurrencyLimit":-1,"additionalParams":"{\"type\": \"LoadBalancer\", \"annotations\": \"annotations:\", \"internalLB\":\"service.beta.kubernetes.io/azure-load-balancer-internal: \\\"true\\\"\", \"kafka_servers\": \"prod-westeurope-kafka-1-broker-1001.internal.logz.io:9092,prod-westeurope-kafka-1-broker-1002.internal.logz.io:9092,prod-westeurope-kafka-1-broker-1003.internal.logz.io:9092\", \"graphite_host\": \"graphite.prod.westeurope.internal.logz.io\", \"consul_server\": \"consul-prod-us-east-1.internal.logz.io\", \"salt_extra\": \"--idle\"}\n"},{"id":65,"name":"logzio-prod-ca-central-1-services","geoRegion":"ca-central-1","availability":"PROD","kubernetesMaster":"https://k8s-1-prod-ca-central-1.internal.logz.io:6443","kubernetesToken":"******","kubernetesCaCert":null,"kubernetesNamespace":"prod","servicePortCoefficient":0,"requireDeploymentMessage":true,"requireHealthCheck":true,"concurrencyLimit":-1,"additionalParams":"{\"type\": \"NodePort\", \"nodePortNginx\": \"nodePort: 30002\", \"nodePortNginxredirect\": \"nodePort: 30011\", \"nodePortHttps\": \"nodePort: 30007\", \"nodePortEngine\": \"nodePort: 30008\", \"az_label\": \"logzio/az:\", \"kafka_servers\": \"prod-ca-central-1-kafka-1-broker-1001.internal.logz.io:9092,prod-ca-central-1-kafka-1-broker-1002.internal.logz.io:9092,prod-ca-central-1-kafka-1-broker-1003.internal.logz.io:9092\", \"graphite_host\": \"graphite.prod.ca-central-1.internal.logz.io\", \"consul_server\": \"consul-prod-ca-central-1.internal.logz.io\", \"salt_extra\": \"--idle\",\"scanners_enabled\": \"scanners: enabled\"}"},{"id":66,"name":"logzio-prod-ca-central-1-le","geoRegion":"ca-central-1","availability":"PROD","kubernetesMaster":"https://k8s-3-prod-ca-central-1.internal.logz.io:6443","kubernetesToken":"******","kubernetesCaCert":null,"kubernetesNamespace":"prod","servicePortCoefficient":0,"requireDeploymentMessage":true,"requireHealthCheck":true,"concurrencyLimit":-1,"additionalParams":"{\"type\": \"NodePort\", \"nodePortNginx\": \"nodePort: 30002\", \"nodePortNginxredirect\": \"nodePort: 30011\", \"nodePortHttps\": \"nodePort: 30007\", \"nodePortEngine\": \"nodePort: 30008\", \"az_label\": \"logzio/az:\", \"kafka_servers\": \"prod-ca-central-1-kafka-1-broker-1001.internal.logz.io:9092,prod-ca-central-1-kafka-1-broker-1002.internal.logz.io:9092,prod-ca-central-1-kafka-1-broker-1003.internal.logz.io:9092\", \"graphite_host\": \"graphite.prod.ca-central-1-all.internal.logz.io\", \"consul_server\": \"consul-prod-ca-central-1.internal.logz.io\", \"salt_extra\": \"--idle\"}"},{"id":67,"name":"logzio-prod-ap-southeast-2-services","geoRegion":"ap-southeast-2","availability":"PROD","kubernetesMaster":"https://k8s-1-prod-ap-southeast-2.internal.logz.io:6443","kubernetesToken":"******","kubernetesCaCert":null,"kubernetesNamespace":"prod","servicePortCoefficient":0,"requireDeploymentMessage":true,"requireHealthCheck":true,"concurrencyLimit":-1,"additionalParams":"{\"type\": \"NodePort\", \"nodePortNginx\": \"nodePort: 30002\", \"nodePortNginxredirect\": \"nodePort: 30011\", \"nodePortHttps\": \"nodePort: 30007\", \"nodePortEngine\": \"nodePort: 30008\", \"az_label\": \"logzio/az:\", \"kafka_servers\": \"prod-ap-southeast-2-kafka-1-broker-1001.internal.logz.io:9092,prod-ap-southeast-2-kafka-1-broker-1002.internal.logz.io:9092,prod-ap-southeast-2-kafka-1-broker-1003.internal.logz.io:9092\", \"graphite_host\": \"graphite.prod.ap-southeast-2.internal.logz.io\", \"consul_server\": \"consul-prod-ap-southeast-2.internal.logz.io\", \"salt_extra\": \"--idle\",\"scanners_enabled\": \"scanners: enabled\"}"},{"id":68,"name":"logzio-prod-ap-southeast-2-le","geoRegion":"ap-southeast-2","availability":"PROD","kubernetesMaster":"https://k8s-3-prod-ap-southeast-2.internal.logz.io:6443","kubernetesToken":"******","kubernetesCaCert":null,"kubernetesNamespace":"prod","servicePortCoefficient":0,"requireDeploymentMessage":true,"requireHealthCheck":true,"concurrencyLimit":-1,"additionalParams":"{\"type\": \"NodePort\", \"nodePortNginx\": \"nodePort: 30002\", \"nodePortNginxredirect\": \"nodePort: 30011\", \"nodePortHttps\": \"nodePort: 30007\", \"nodePortEngine\": \"nodePort: 30008\", \"az_label\": \"logzio/az:\", \"kafka_servers\": \"prod-ap-southeast-2-kafka-1-broker-1001.internal.logz.io:9092,prod-ap-southeast-2-kafka-1-broker-1002.internal.logz.io:9092,prod-ap-southeast-2-kafka-1-broker-1003.internal.logz.io:9092\", \"graphite_host\": \"graphite.prod.ap-southeast-2-all.internal.logz.io\", \"consul_server\": \"consul-prod-ap-southeast-2.internal.logz.io\", \"salt_extra\": \"--idle\"}"},{"id":69,"name":"logzio-prod-westus2-services","geoRegion":"westus2","availability":"PROD","kubernetesMaster":"https://logzio-westus2-prod-aks-1-services-31a82d14.hcp.westus2.azmk8s.io:443","kubernetesToken":"******","kubernetesCaCert":"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","kubernetesNamespace":"prod","servicePortCoefficient":0,"requireDeploymentMessage":true,"requireHealthCheck":true,"concurrencyLimit":-1,"additionalParams":"{\"type\": \"LoadBalancer\", \"annotations\": \"annotations:\", \"internalLB\":\"service.beta.kubernetes.io/azure-load-balancer-internal: \\\"true\\\"\", \"kafka_servers\": \"prod-westus2-kafka-1-broker-1001.internal.logz.io:9092,prod-westus2-kafka-1-broker-1002.internal.logz.io:9092,prod-westus2-kafka-1-broker-1003.internal.logz.io:9092\", \"graphite_host\": \"graphite.prod.westus2.internal.logz.io\", \"consul_server\": \"consul-prod-us-east-1.internal.logz.io\", \"salt_extra\": \"--idle\"}"},{"id":70,"name":"logzio-prod-westus2-logengines","geoRegion":"westus2","availability":"PROD","kubernetesMaster":"https://logzio-westus2-prod-aks-2-logengines-06278ae3.hcp.westus2.azmk8s.io:443","kubernetesToken":"******","kubernetesCaCert":"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","kubernetesNamespace":"prod","servicePortCoefficient":0,"requireDeploymentMessage":true,"requireHealthCheck":true,"concurrencyLimit":-1,"additionalParams":"{\"type\": \"LoadBalancer\", \"annotations\": \"annotations:\", \"internalLB\":\"service.beta.kubernetes.io/azure-load-balancer-internal: \\\"true\\\"\", \"kafka_servers\": \"prod-westus2-kafka-1-broker-1001.internal.logz.io:9092,prod-westus2-kafka-1-broker-1002.internal.logz.io:9092,prod-westus2-kafka-1-broker-1003.internal.logz.io:9092\", \"graphite_host\": \"graphite.prod.westus2.internal.logz.io\", \"consul_server\": \"consul-prod-us-east-1.internal.logz.io\", \"salt_extra\": \"--idle\"}"},{"id":71,"name":"logzio-prod-westus2-scanners","geoRegion":"westus2","availability":"PROD","kubernetesMaster":"https://logzio-westus2-prod-aks-4-scanners-d8914f8b.hcp.westus2.azmk8s.io:443","kubernetesToken":"******","kubernetesCaCert":"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","kubernetesNamespace":"prod","servicePortCoefficient":0,"requireDeploymentMessage":true,"requireHealthCheck":true,"concurrencyLimit":-1,"additionalParams":"{\"type\": \"LoadBalancer\", \"annotations\": \"annotations:\", \"internalLB\":\"service.beta.kubernetes.io/azure-load-balancer-internal: \\\"true\\\"\", \"kafka_servers\": \"prod-westus2-kafka-1-broker-1001.internal.logz.io:9092,prod-westus2-kafka-1-broker-1002.internal.logz.io:9092,prod-westus2-kafka-1-broker-1003.internal.logz.io:9092\", \"graphite_host\": \"graphite.prod.westus2.internal.logz.io\", \"consul_server\": \"consul-prod-us-east-1.internal.logz.io\", \"salt_extra\": \"--idle\"}"}];
export const stackEnvironmentsMock = [{"id":1,"name":"Production Logengines","stackType":"ENVIRONMENTS","environments":[51,52,59,66,68,70],"enabled":true},{"id":2,"name":"Non-LE Prod envs","stackType":"ENVIRONMENTS","environments":[5,9,58,65,67,69],"enabled":true},{"id":3,"name":"Staging","stackType":"ENVIRONMENTS","environments":[2,7],"enabled":true}];
